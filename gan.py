# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12jhsRE2JVb4-3uA2oaamcduqaBjp0k9U
"""

# Import necessary libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from skimage.transform import resize
import imageio
import glob
import os
from google.colab import files
import shutil

"""### Data Loading"""

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py

from helper_functions import unzip_data

files.upload()

os.makedirs("/root/.kaggle/", exist_ok=True)

shutil.move("kaggle.json", "/root/.kaggle/kaggle.json")

os.chmod("/root/.kaggle/kaggle.json", 0o600)

!kaggle datasets download -d dhruvverma8291/adni-dataset-cvdv

unzip_data("/content/minor-dataset.zip")

t1_path = "/content/ADNI 1 KAAGGLE/AD"

t1_images = os.listdir(t1_path)

t1_images[2]

imageio.imread(t1_path+ '/' + t1_images[2])

from skimage.transform import resize
import imageio
import numpy as np

def extract_images(ospath, imgfolder, target_shape=(128, 128)):
    img_list = []
    for file in imgfolder:
        img = imageio.imread(ospath + '/' + file)
        img_resized = resize(img, target_shape, preserve_range=True, anti_aliasing=True).astype(img.dtype)
        img_list.append(img_resized)
    return np.asarray(img_list)

t1 = extract_images(t1_path, t1_images)

print('T1 Shape: ',t1.shape)

print('Dataset size: ', t1.shape[0])

"""### Data Visualization

"""

# Visualizing t1 image
plt.figure(figsize=(2, 2))
plt.imshow(t1[2], cmap='gray')
plt.axis('off')
plt.show()

"""### Data Preprocessing"""

def normalize(img):
    img = (img/127.5)-1.0
    return img

t1 = normalize(t1)

plt.figure(figsize=(2, 2))
plt.imshow(t1[2], cmap='gray')
plt.axis('off')
plt.show()

"""### Model Building & Training"""

data_dir = "/content/registered_images"

final_dataset_AD = tf.keras.utils.image_dataset_from_directory(data_dir,
                                                            labels = None,
                                                            label_mode = None,
                                                            color_mode = "grayscale",
                                                            batch_size = 32,
                                                            image_size = (128,128),
                                                            shuffle = True,
                                                            seed = 42
                                                            )

def normalize_img(img):

    img = tf.cast(img, tf.float32) / 127.5 - 1.0
    return img


final_dataset_AD = final_dataset_AD.map(lambda x: normalize_img(x), num_parallel_calls=tf.data.AUTOTUNE)

final_dataset_AD = final_dataset_AD.prefetch(tf.data.AUTOTUNE)

for batch in final_dataset_AD.take(1):
    print("Batch shape:", batch.shape)
    print("Min/max:", tf.reduce_min(batch).numpy(), tf.reduce_max(batch).numpy())

t1_sample_AD = next(iter(final_dataset_AD))
plt.figure(figsize=(2, 2))
plt.imshow(t1_sample_AD[0].numpy()[:, :, 0], cmap='gray')
plt.title('T1 MRI')
plt.axis('off')
plt.show()

class InstanceNormalization(tf.keras.layers.Layer):
    def __init__(self, epsilon=1e-5):
        super(InstanceNormalization, self).__init__()
        self.epsilon = epsilon

    def build(self, input_shape):
        self.scale = self.add_weight(
            name='scale',
            shape=input_shape[-1:],
            initializer=tf.random_normal_initializer(1., 0.02),
            trainable=True)
        self.offset = self.add_weight(
            name='offset',
            shape=input_shape[-1:],
            initializer='zeros',
            trainable=True)

    def call(self, x):
        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)
        inv = tf.math.rsqrt(variance + self.epsilon)
        normalized = (x - mean) * inv
        return self.scale * normalized + self.offset

def downsample(filters, size, apply_norm=True):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = tf.keras.Sequential()
    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',
                                      kernel_initializer=initializer, use_bias=False))
    if apply_norm:
        result.add(InstanceNormalization())

    result.add(tf.keras.layers.LeakyReLU())
    return result

def upsample(filters, size, apply_dropout=False):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = tf.keras.Sequential()
    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',
                                               kernel_initializer=initializer, use_bias=False))
    result.add(InstanceNormalization())
    if apply_dropout:
        result.add(tf.keras.layers.Dropout(0.5))

    result.add(tf.keras.layers.ReLU())
    return result

def unet_generator():
    down_stack = [
        downsample(128, 4, False),
        downsample(256, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4)
    ]
    up_stack = [
        upsample(512, 4, True),
        upsample(512, 4, True),
        upsample(512, 4, True),
        upsample(256, 4),
        upsample(256, 4),
        upsample(128, 4)
    ]
    initializer = tf.random_normal_initializer(0., 0.02)
    last = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, padding='same', kernel_initializer=initializer,
                                           activation='tanh')
    concat = tf.keras.layers.Concatenate()
    inputs = tf.keras.layers.Input(shape=[128, 128, 1])
    x = inputs

    skips = []
    for down in down_stack:
        x = down(x)
        skips.append(x)

    skips = reversed(skips[:-1])

    for up, skip in zip(up_stack, skips):
        x = up(x)
        x = concat([x, skip])
    x = last(x)
    return tf.keras.Model(inputs=inputs, outputs=x)

"""#### Creating generator"""

generator_t1= unet_generator()

generator_t1.summary()

"""#### Creating Discriminator"""

def discriminator():
    initializer = tf.random_normal_initializer(0., 0.02)

    inp = tf.keras.layers.Input(shape=[128, 128, 1], name='input_image')
    x = inp


    down1 = downsample(128, 4, False)(x)
    down2 = downsample(256, 4)(down1)
    down3 = downsample(512, 4)(down2)
    down4 = downsample(512, 4)(down3)
    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down2)

    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1)
    norm1 = InstanceNormalization()(conv)
    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)

    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)

    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)
    return tf.keras.Model(inputs=inp, outputs=last)

discriminator_t1 = discriminator()

discriminator_t1.summary()

"""### Model Training"""

conv_to_t1 = generator_t1(t1_sample_AD)

plt.figure(figsize=(4, 4))

imgs = [t1_sample_AD, conv_to_t1]
title = ['t1_image', 'conv_to_t1']

for i in range(len(imgs)):
    plt.subplot(2, 2, i+1)
    plt.title(title[i])
    plt.imshow(imgs[i][0].numpy()[:, :, 0], cmap='gray')
    plt.axis('off')
plt.show()

"""#### Creating loss objects and functions"""

# Classification loss of discriminator: BCE Loss
loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)

# Discriminator Loss: Real Loss + Fake Loss)
def discriminator_loss(real, generated):
    real_loss = loss_obj(tf.ones_like(real), real)
    generated_loss = loss_obj(tf.zeros_like(generated), generated)
    total_disc_loss = real_loss + generated_loss
    return total_disc_loss * 0.5 # mean of losses

# Generator Loss: Discriminator loss on generated data
def generator_loss(generated):
    return loss_obj(tf.ones_like(generated), generated)

# Cycle Loss: When we use both of Generators sequentially on a Input Image, we get Cycle Image and
# the L1 Loss between these two is called Cycle Loss.
def calc_cycle_loss(real_image, cycled_image):
    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))
    return 10.0 * loss1

# Identity Loss: When we provide input image to the Generator such that no translation is needed
# because the image is already transformed, here also we take L1 Loss between Input and Output Image.
def identity_loss(real_image, same_image):
    loss = tf.reduce_mean(tf.abs(real_image - same_image))
    return 0.5*loss

initial_learning_rate = 2e-4
lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=1000,
    decay_rate=0.96,
    staircase=True)

generator_t1_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

discriminator_t1_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

EPOCHS = 200

"""#### Checkpoint Initialization"""

# Initialize checkpoints to save models
checkpoint_path = "./Trained_Model_pro"

ckpt = tf.train.Checkpoint(generator_t1=generator_t1,
                           discriminator_t1=discriminator_t1,

                           generator_g_optimizer=generator_t1_optimizer,

                           discriminator_x_optimizer=discriminator_t1_optimizer,
                           )

ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)

if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint)
    print ('Latest checkpoint restored!!')

def generate_images(model, test_input):
    prediction = model(test_input)

    plt.figure(figsize=(8, 4))
    display_list = [test_input[0], prediction[0]]
    title = ['Input Image', 'Generated Image']
    for i in range(4):
        plt.subplot(1, 4, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i].numpy()[:, :, 0], cmap='gray')
        plt.axis('off')

    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

"""#### Defining Training Function"""

@tf.function
def train_step(real_x):
    # multiple gradient calculations
    with tf.GradientTape(persistent=True) as tape:
        # Forward pass
        fake_x = generator_t1(real_x, training=True)
        cycled_x = generator_t1(fake_x, training=True)

        # Discriminator evaluations
        disc_real = discriminator_t1(real_x, training=True)
        disc_fake = discriminator_t1(fake_x, training=True)

        # Calculate losses
        gen_loss = generator_loss(disc_fake)
        cycle_loss = calc_cycle_loss(real_x, cycled_x)
        total_gen_loss = gen_loss + cycle_loss

        # Discriminator loss with label smoothing
        real_labels = tf.ones_like(disc_real) * 0.9
        fake_labels = tf.zeros_like(disc_fake) + tf.random.uniform(
            tf.shape(disc_fake), 0, 0.1)

        disc_loss_real = tf.keras.losses.binary_crossentropy(
            real_labels, disc_real, from_logits=True)
        disc_loss_fake = tf.keras.losses.binary_crossentropy(
            fake_labels, disc_fake, from_logits=True)
        total_disc_loss = tf.reduce_mean(disc_loss_real + disc_loss_fake)

    # Calculate gradients
    gen_gradients = tape.gradient(total_gen_loss, generator_t1.trainable_variables)
    disc_gradients = tape.gradient(total_disc_loss, discriminator_t1.trainable_variables)

    # Apply gradients
    generator_t1_optimizer.apply_gradients(
        zip(gen_gradients, generator_t1.trainable_variables))
    discriminator_t1_optimizer.apply_gradients(
        zip(disc_gradients, discriminator_t1.trainable_variables))

    return total_gen_loss, total_disc_loss

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for epoch in range(1, EPOCHS+1):
#     epoch_gen_loss = []
#     epoch_disc_loss = []
# 
#     # Iterate through batches
#     for step, image_x in enumerate(final_dataset_AD):
# 
#         if tf.shape(image_x)[0] == 0:
#             print(f"Skipping empty batch at step {step}")
#             continue
# 
#         try:
#             gen_loss, disc_loss = train_step(image_x)
#             epoch_gen_loss.append(gen_loss)
#             epoch_disc_loss.append(disc_loss)
# 
#             if step % 100 == 0:
#                 print(f"Epoch {epoch} Step {step} | Gen Loss: {gen_loss:.4f} | Disc Loss: {disc_loss:.4f}")
#         except Exception as e:
#             print(f"Error at step {step}: {e}")
#             continue
# 
#     # Only generate images if we have training data
#     if len(epoch_gen_loss) > 0:
#         try:
#             generate_images(generator_t1, t1_sample_AD)
#         except Exception as e:
#             print(f"Error generating images: {e}")
# 
#     if epoch % 5 == 0:
#         try:
#             ckpt_save_path = ckpt_manager.save()
#             print(f'Saving checkpoint for epoch {epoch} at {ckpt_save_path}')
#         except Exception as e:
#             print(f"Error saving checkpoint: {e}")
# 
#     # Print epoch statistics only if we have data
#     if len(epoch_gen_loss) > 0:
#         avg_gen = tf.reduce_mean(epoch_gen_loss).numpy()
#         avg_disc = tf.reduce_mean(epoch_disc_loss).numpy()
#         print(f"\nEpoch {epoch} Summary:")
#         print(f"Generator Loss: {avg_gen:.4f} | Discriminator Loss: {avg_disc:.4f}")
#     else:
#         print(f"\nEpoch {epoch} had no valid batches")
# 
#     print("-" * 50 + "\n")
#

!zip -r Trained_Model_pro.zip Trained_Model_pro

import os
import matplotlib.pyplot as plt
import tensorflow as tf

# Directory to save generated images
augmented_dir = "augmented_images_final"
os.makedirs(augmented_dir, exist_ok=True)

def save_generated_images(generator, dataset, num_batches, prefix="aug"):
    image_count = 0

    for i, image_batch in enumerate(dataset.take(num_batches)):
        # Generate images
        generated_batch = generator(image_batch, training=False)

        for j in range(generated_batch.shape[0]):
            generated_image = generated_batch[j].numpy()

            # Convert to grayscale if needed
            if generated_image.shape[-1] == 1:
                generated_image = generated_image[:, :, 0]
                cmap = 'gray'
            else:
                cmap = None

            # Save image
            plt.imsave(
                os.path.join(augmented_dir, f"{prefix}_{image_count:05d}.png"),
                generated_image,
                cmap=cmap
            )
            image_count += 1

    print(f"Saved {image_count} augmented images to '{augmented_dir}'.")

# Example usage
save_generated_images(generator_t1, final_dataset_AD, num_batches=16)

!zip -r augmented_images_final.zip augmented_images_final

